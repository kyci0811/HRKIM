import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules
import streamlit as st
import plotly.express as px
import networkx as nx
import matplotlib.pyplot as plt

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ¯ ì§ë¬´ ê²½ë¡œ ì˜ˆì¸¡ê¸°",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ì‚¬ì´ë“œë°” ì œëª© ë° ì„¤ëª…
st.sidebar.title("ğŸ“Š ì„¤ì •")
st.sidebar.markdown("""
    **ì§ë¬´ ê²½ë¡œ ì˜ˆì¸¡ì„ ìœ„í•œ ì„¤ì •ì„ ì¡°ì •í•˜ì„¸ìš”.**
""")

# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜
@st.cache_data
def load_and_prepare_data(filepath=None):
    try:
        if filepath is None:
            # ë‚´ì¥ëœ ë°ì´í„°ì…‹ ì‚¬ìš©
            df = pd.read_csv('path_dataset.csv', encoding='utf-8')
        else:
            # ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŒŒì¼ ì‚¬ìš©
            for encoding in ['utf-8', 'cp949', 'euc-kr']:
                try:
                    df = pd.read_csv(filepath, encoding=encoding, sep=None, engine='python')
                    if not df.empty:
                        break
                except UnicodeDecodeError:
                    continue
                except Exception as e:
                    continue
        
        if df.empty:
            st.error("ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CSV íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return [], []
            
        # ì§ë¬´ ê²½ë¡œë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
        df['career_path'] = df.iloc[:, 1:].apply(
            lambda x: ','.join([str(pos) for pos in x if pd.notna(pos) and str(pos).strip()]), axis=1
        )
        
        # ì§ë¬´ ê²½ë¡œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        career_paths = df['career_path'].str.split(',').tolist()
        
        # ìœ ë‹ˆí¬í•œ ì§ë¬´ ëª©ë¡ ìƒì„±
        unique_positions = sorted(set([pos.strip() for path in career_paths for pos in path if pos.strip()]))
        
        return career_paths, unique_positions
        
    except Exception as e:
        st.error(f"ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return [], []

# ì—°ê´€ì„± ê·œì¹™ ìƒì„± í•¨ìˆ˜
@st.cache_data
def generate_rules(career_paths, unique_positions, min_support=0.001, min_confidence=0.1):
    try:
        # íŠ¸ëœì­ì…˜ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        transactions = pd.DataFrame([
            {pos: (pos in path) for pos in unique_positions}
            for path in career_paths if path
        ])
        
        # Apriori ì•Œê³ ë¦¬ì¦˜ ì ìš© - max_len íŒŒë¼ë¯¸í„° ì¶”ê°€
        frequent_itemsets = apriori(
            transactions,
            min_support=min_support,
            use_colnames=True,
            max_len=3  # ìµœëŒ€ ì•„ì´í…œ ì¡°í•© ê°œìˆ˜ ì„¤ì •
        )
        
        if frequent_itemsets.empty:
            return pd.DataFrame(columns=['antecedents', 'consequents', 'support', 'confidence', 'lift'])
        
        # ì—°ê´€ì„± ê·œì¹™ ìƒì„± - metricê³¼ min_threshold ì¡°ì •
        rules = association_rules(
            frequent_itemsets,
            metric="confidence",
            min_threshold=min_confidence,
            support_only=False  # ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ ê³„ì‚°
        )
        
        if not rules.empty:
            # ê·œì¹™ í•„í„°ë§ ë° ì •ë ¬
            rules = rules[
                (rules['lift'] > 1.0) &  # ì–‘ì˜ ìƒê´€ê´€ê³„ë§Œ ì„ íƒ
                (rules['antecedents'].apply(len) <= 2)  # ì„ í–‰í•­ëª© ê°œìˆ˜ ì œí•œ
            ]
            rules = rules.sort_values(['confidence', 'lift', 'support'], ascending=[False, False, False])
        
        return rules
        
    except Exception as e:
        st.error(f"ì—°ê´€ ê·œì¹™ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return pd.DataFrame(columns=['antecedents', 'consequents', 'support', 'confidence', 'lift'])

# ë‹¤ìŒ ì§ë¬´ ì˜ˆì¸¡ í•¨ìˆ˜
def predict_next_position(current_positions, rules):
    try:
        if rules.empty:
            return "ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # í˜„ì¬ ì§ë¬´ì™€ ê´€ë ¨ëœ ê·œì¹™ ì°¾ê¸°
        relevant_rules = rules[rules['antecedents'].apply(
            lambda x: any(pos in x for pos in current_positions)
        )]
        
        if relevant_rules.empty:
            return "ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì‹ ë¢°ë„ì™€ í–¥ìƒë„ë¡œ ì •ë ¬
        relevant_rules = relevant_rules.sort_values(['confidence', 'lift'], ascending=[False, False])
        
        # í˜„ì¬ ì§ë¬´ì— ì—†ëŠ” ìƒˆë¡œìš´ ì§ë¬´ ì°¾ê¸°
        for _, rule in relevant_rules.iterrows():
            consequents = list(rule['consequents'])  # frozensetì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            for consequent in consequents:
                if consequent not in current_positions:
                    return f"{consequent} (ì‹ ë¢°ë„: {rule['confidence']:.2%}, í–¥ìƒë„: {rule['lift']:.2f})"
        
        return "ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
    except Exception as e:
        st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return "ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# ì—°ê´€ ê·œì¹™ ì‹œê°í™” í•¨ìˆ˜ - ì‚°ì ë„
def plot_rules_scatter(rules):
    if rules.empty:
        st.warning("ì—°ê´€ ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    # Create a copy and convert 'antecedents' and 'consequents' to strings
    rules_plot = rules.copy()
    rules_plot['antecedents_str'] = rules_plot['antecedents'].apply(lambda x: ', '.join(x))
    rules_plot['consequents_str'] = rules_plot['consequents'].apply(lambda x: ', '.join(x))
    fig = px.scatter(
        rules_plot,
        x='support',
        y='confidence',
        size='lift',
        color='lift',
        hover_data=['antecedents_str', 'consequents_str'],
        title='ì—°ê´€ ê·œì¹™ì˜ ì§€ì§€ë„ì™€ ì‹ ë¢°ë„ ë¶„í¬',
        labels={'support': 'ì§€ì§€ë„', 'confidence': 'ì‹ ë¢°ë„', 'lift': 'í–¥ìƒë„'}
    )
    fig.update_layout(template='plotly_dark')
    return fig

# ì—°ê´€ ê·œì¹™ ì‹œê°í™” í•¨ìˆ˜ - ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„
def plot_rules_network(rules):
    if rules.empty:
        st.warning("ì—°ê´€ ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤.")
        return plt.figure()
    
    G = nx.Graph()
    for _, row in rules.iterrows():
        for antecedent in row['antecedents']:
            for consequent in row['consequents']:
                G.add_edge(antecedent, consequent, weight=row['lift'])
    
    pos = nx.spring_layout(G, k=0.5)
    edge_weights = [G[u][v]['weight'] for u, v in G.edges()]
    node_sizes = [500 + 500 * nx.degree(G, node) for node in G.nodes()]
    
    plt.figure(figsize=(10, 8))
    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='skyblue', alpha=0.7)
    nx.draw_networkx_edges(G, pos, width=[w * 0.5 for w in edge_weights], alpha=0.5)
    nx.draw_networkx_labels(G, pos, font_size=10, font_family='sans-serif')
    plt.title('ì—°ê´€ ê·œì¹™ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„', fontsize=15)
    plt.axis('off')
    plt.tight_layout()
    return plt

# Streamlit ì•±
st.title('ğŸ¯ **ì§ë¬´ ê²½ë¡œ ì˜ˆì¸¡ê¸°**')
st.markdown("""
    í˜„ì¬ê¹Œì§€ì˜ ì§ë¬´ ê²½ë¡œë¥¼ ì„ íƒí•˜ë©´ ë‹¤ìŒ ì§ë¬´ë¥¼ ì˜ˆì¸¡í•´ë“œë¦½ë‹ˆë‹¤.
    
    ê¸°ë³¸ ë°ì´í„°ì…‹ì´ ë‚´ì¥ë˜ì–´ ìˆìœ¼ë©°, ì›í•˜ì‹œëŠ” ê²½ìš° ì‚¬ì´ë“œë°”ì—ì„œ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")

# íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒì‚¬í•­)
uploaded_file = st.sidebar.file_uploader("ì‚¬ìš©ì ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ (CSV, ì„ íƒì‚¬í•­)", type="csv")

# ë°ì´í„° ë¡œë“œ
career_paths, unique_positions = load_and_prepare_data(uploaded_file)

if not career_paths:
    st.stop()

# ì‚¬ì´ë“œë°” ì„¤ì •
min_support = st.sidebar.slider('ìµœì†Œ ì§€ì§€ë„', min_value=0.0, max_value=0.1, value=0.001, step=0.001)
min_confidence = st.sidebar.slider('ìµœì†Œ ì‹ ë¢°ë„', min_value=0.0, max_value=1.0, value=0.1, step=0.05)

# ì—°ê´€ ê·œì¹™ ìƒì„±
rules = generate_rules(career_paths, unique_positions, min_support, min_confidence)

st.sidebar.markdown("### ğŸ” ê·œì¹™ í•„í„°ë§")
st.sidebar.markdown(f"ì´ ë°œê²¬ëœ ê·œì¹™ ìˆ˜: **{len(rules)}**")

# ì§ë¬´ ì„ íƒ UIë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.markdown("### 1ë‹¨ê³„")
    pos1 = st.selectbox(
        'ì²« ë²ˆì§¸ ì§ë¬´',
        options=['ì„ íƒí•˜ì„¸ìš”'] + unique_positions,
        key='pos1'
    )

with col2:
    st.markdown("### 2ë‹¨ê³„")
    pos2 = st.selectbox(
        'ë‘ ë²ˆì§¸ ì§ë¬´',
        options=['ì„ íƒí•˜ì„¸ìš”'] + unique_positions,
        key='pos2'
    )

with col3:
    st.markdown("### 3ë‹¨ê³„")
    pos3 = st.selectbox(
        'ì„¸ ë²ˆì§¸ ì§ë¬´',
        options=['ì„ íƒí•˜ì„¸ìš”'] + unique_positions,
        key='pos3'
    )

with col4:
    st.markdown("### 4ë‹¨ê³„")
    pos4 = st.selectbox(
        'ë„¤ ë²ˆì§¸ ì§ë¬´',
        options=['ì„ íƒí•˜ì„¸ìš”'] + unique_positions,
        key='pos4'
    )

# ì„ íƒëœ ì§ë¬´ ìˆ˜ì§‘
selected_positions = [pos for pos in [pos1, pos2, pos3, pos4] if pos != 'ì„ íƒí•˜ì„¸ìš”']

# ì˜ˆì¸¡ ë²„íŠ¼
if st.button('ğŸ”® ë‹¤ìŒ ì§ë¬´ ì˜ˆì¸¡í•˜ê¸°', type='primary'):
    if selected_positions:
        next_position = predict_next_position(selected_positions, rules)
        
        st.markdown("---")
        st.markdown("### ğŸ¯ **ì˜ˆì¸¡ ê²°ê³¼**")
        if next_position != "ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.":
            st.success(f"**ë‹¤ìŒ ì˜ˆìƒ ì§ë¬´:** {next_position}")
            
            relevant_rules = rules[rules['antecedents'].apply(
                lambda x: all(pos in x for pos in selected_positions)
            )]
            relevant_rules = relevant_rules[relevant_rules['consequents'].apply(
                lambda x: next_position in x
            )]
            
            if not relevant_rules.empty:
                confidence = relevant_rules.iloc[0]['confidence']
                support = relevant_rules.iloc[0]['support']
                lift = relevant_rules.iloc[0]['lift']
                
                st.markdown("#### **ì—°ê´€ ê·œì¹™ ì„¸ë¶€ ì •ë³´**")
                col_a, col_b, col_c = st.columns(3)
                with col_a:
                    st.metric(label="**ì‹ ë¢°ë„**", value=f"{confidence:.2%}")
                with col_b:
                    st.metric(label="**ì§€ì§€ë„**", value=f"{support:.2%}")
                with col_c:
                    st.metric(label="**í–¥ìƒë„**", value=f"{lift:.2f}")
        else:
            st.error("ì„ íƒí•˜ì‹  ì§ë¬´ ê²½ë¡œì— ëŒ€í•œ ì˜ˆì¸¡ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            st.info("ë‹¤ë¥¸ ì§ë¬´ ì¡°í•©ì„ ì„ íƒí•´ë³´ì„¸ìš”.")
    else:
        st.warning('ğŸ”” ìµœì†Œ í•œ ê°œ ì´ìƒì˜ ì§ë¬´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.')

# í˜„ì¬ ì„ íƒëœ ê²½ë¡œ í‘œì‹œ
if selected_positions:
    st.markdown("---")
    st.markdown("### ğŸ“‹ **ì„ íƒí•œ ì§ë¬´ ê²½ë¡œ**")
    career_path = " â†’ ".join(selected_positions)
    st.markdown(f"**{career_path}**")

# ì—°ê´€ ê·œì¹™ ì‹œê°í™”
if not rules.empty:
    st.markdown("---")
    st.markdown("### ğŸ“ˆ **ì—°ê´€ ê·œì¹™ ì‹œê°í™”**")
    
    # ì‚°ì ë„
    fig = plot_rules_scatter(rules)
    if fig:
        st.plotly_chart(fig, use_container_width=True)
    
    # ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„
    st.markdown("#### ğŸ”— ì—°ê´€ ê·œì¹™ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„")
    plt_fig = plot_rules_network(rules)
    if plt_fig:
        st.pyplot(plt_fig)
else:
    st.info("ì„¤ì •ëœ ìµœì†Œ ì§€ì§€ë„ ë° ì‹ ë¢°ë„ ê¸°ì¤€ì— ë§ëŠ” ì—°ê´€ ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤.")

# ì—°ê´€ ê·œì¹™ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
if not rules.empty:
    # Convert 'antecedents' and 'consequents' to strings for CSV
    rules_download = rules.copy()
    rules_download['antecedents'] = rules_download['antecedents'].apply(lambda x: ', '.join(x))
    rules_download['consequents'] = rules_download['consequents'].apply(lambda x: ', '.join(x))
    
    st.markdown("---")
    st.download_button(
        label="ğŸ“¥ ì—°ê´€ ê·œì¹™ ë‹¤ìš´ë¡œë“œ",
        data=rules_download.to_csv(index=False),
        file_name='association_rules.csv',
        mime='text/csv',
    )
